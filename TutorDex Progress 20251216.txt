TutorDex Progress Report (Public Beta / V1.0 Readiness)
Generated: 2025-12-16
Repo location scanned: D:\TutorDex

================================================================================
1) What TutorDex Is (from TutorDex background info.txt)
================================================================================
TutorDex is a tuition-assignment aggregator and distribution layer.

Core premise:
- The tuition assignment market is fragmented across many Telegram agency channels.
- Tutors waste time scanning noisy, duplicate, and inconsistently formatted posts.
- TutorDex aggregates assignments island-wide into a single surface (Telegram + website),
  then pushes “sniper” DMs to tutors based on preferences for speed/edge.

Business direction in the background doc:
- Free tier should feel powerful; paid is for amplification/precision, not access.
- Long-term monetisation is primarily from agencies (commissions/subscriptions + analytics),
  not from desperate tutors.
- Censorship/anti-scrape is planned later to protect data/moat once competitors emerge.

Milestones (as defined in the background doc):
1. Aggregation Accuracy
2. Soft Monetisation (Not Forced)
3. Tutor Behaviour Shift
4. Dependence via Personalisation
5. Intelligence Accumulation
6. Application Flow Centralisation
7. First Agency Dependence
8. Scalable Agency Monetisation (Endgame)

================================================================================
2) What’s Implemented Today (brief summary)
================================================================================
There are three main components:

A) TutorDexAggregator (Telegram ingestion + extraction + broadcast)
- Telethon-based reader listens to configured channels and processes new posts.
- Filters:
  - Skips forwarded posts.
  - Detects and skips “compilation” messages (multi-assignment / compilation-like), logging
    skipped excerpts to a JSONL file for later review.
  - Basic “already processed” guard via `processed_ids.json`.
- Extraction:
  - Uses a local OpenAI-compatible LLM HTTP API (LM Studio etc.) to extract structured JSON.
  - Schema includes: assignment code, type, subjects, level, address/postal, rate, schedule, etc.
  - Includes best-effort postal code estimation via OSM Nominatim if postal is missing.
- Output:
  - Broadcasts formatted HTML messages to a Telegram channel via Bot API.
  - Optional fallback to JSONL file if bot configuration is missing.
- Persistence (optional, enabled in practice based on logs):
  - Upserts assignments into Supabase (PostgREST) with dedupe + bump count.
  - Supports both minimal single-table schema and a normalized schema with agencies table.
- DM matching (optional):
  - Can call a matching backend to get tutor chat IDs and send DMs via a separate bot.
- Ops:
  - Structured logging + rotating file logs in `TutorDexAggregator/logs/`.
  - Windows Task Scheduler helper scripts in `TutorDexAggregator/setup_service/`.

B) TutorDexBackend (FastAPI “matching + preferences + analytics” service)
- FastAPI service with:
  - Redis tutor preference store (Upstash-compatible).
  - Matching endpoint that scores tutors for an assignment payload.
  - “Link code” flow to attach a Telegram chat_id to a tutor (Firebase uid).
  - Optional Supabase persistence for users/preferences/events (service role key).
  - Optional Firebase Admin verification for Bearer tokens.
- Docker support + docker-compose file at repo root for backend + link-bot poller.

C) TutorDexWebsite (Firebase Hosted static site)
- Static multi-page site (Vite build -> Firebase Hosting).
- Firebase Auth implemented:
  - Email/password + Google sign-in.
  - “Require auth” gate for Assignments/Profile pages.
- Assignments page:
  - Filters by level, specific level, subject, location, min rate.
  - Loads “open” assignments from Supabase REST (anon key) if configured; otherwise uses mock data.
  - Records a basic analytics event (“assignments_view”) via the backend if configured.
- Profile page:
  - Lets signed-in users save preferences (subjects/levels pairs, assignment types, tutor type, learning modes).
  - Calls backend `/me/tutor` (Bearer token) to store preferences in Redis and (optionally) Supabase.
  - Generates a Telegram link code and instructs the user to message the DM bot `/link <code>`.

================================================================================
3) What the System Is Currently Collecting (from local logs + code)
================================================================================

Local files that exist on this server:
- TutorDexAggregator/logs/tutordex_aggregator.log
  - Rotating log file with pipeline events and timings.
  - Observed events include: telegram_connected, watching_channel, message_skipped,
    LLM extraction start/ok, enrichment summaries, Supabase persist results, broadcast_sent,
    DM matching results, and per-message pipeline_summary with step timings.
  - Also contains Telethon notices about missing `cryptg` / SSL lib (performance degradation).

- TutorDexAggregator/compilations.jsonl
  - JSON Lines of messages flagged as “compilation_detected”.
  - Each entry includes: timestamp, channel id/username/title, message link, reason, excerpt.
  - This is a valuable audit stream for tuning compilation detection and/or later parsing
    multi-assignment posts into individual assignments.

- TutorDexAggregator/processed_ids.json
  - Local dedupe list of “channel_id:message_id” that have been processed.

Supabase data written by the system (based on schemas + code paths):

Assignments (table: `assignments`)
- Source: TutorDexAggregator/supabase_persist.py
- Core fields written include (non-exhaustive):
  - Identifiers: external_id (assignment_code if present else tg:channel_id:message_id), message_link
  - Agency metadata: agency_name (channel title), agency_link (t.me/username)
  - Parsed fields: subject/subjects, level, specific_student_level, type, address, postal_code,
    learning_mode, genders, frequency, duration, hourly_rate, rate_min/rate_max,
    time_slots, estimated_time_slots, time_slots_note, additional_remarks
  - Raw payload snapshots: payload_json, parsed_json
  - Lifecycle: created_at, last_seen, bump_count, status (open/closed)
- Behavior:
  - On duplicates, it updates `last_seen` and conditionally increments `bump_count`
    based on `SUPABASE_BUMP_MIN_SECONDS` (default 6 hours).
  - There is also a script to auto-close stale “open” assignments: `expire_assignments.py`.

User Preferences and Analytics (normalized schema path)
- Source: TutorDexBackend/supabase_store.py + TutorDexBackend/app.py
- Tables defined in `TutorDexAggregator/supabase_schema_full.sql`:
  - users (firebase_uid, name, email, timestamps)
  - user_preferences (subjects, levels, subject_pairs, assignment_types, tutor_kinds, learning_modes)
  - analytics_events (user_id, assignment_id, event_type, event_time, meta jsonb)
  - analytics_daily (daily rollups)
- Website currently emits (when backend configured):
  - assignments_view
  - profile_save
  - (No “apply click”, “DM delivered/opened”, “subscription”, etc. yet.)

Redis (Upstash) data written by the system
- Source: TutorDexBackend/redis_store.py
- Stores tutor preference documents keyed by `tutordex:tutor:{tutor_id}` (tutor_id = Firebase uid).
- Stores chat_id (Telegram DM destination) once linked via the link-code flow.

================================================================================
4) Implementation vs Background Milestones (status)
================================================================================

Milestone 1 – Aggregation Accuracy: PARTIALLY IMPLEMENTED
Implemented:
- Multi-channel Telegram ingestion and broadcasting works.
- LLM-based extraction into a structured schema exists.
- Duplicate handling exists (processed ids + Supabase bump_count on repeats).
- Compilation-like post detection exists and is logged for review.
Gaps (must close for public beta quality):
- Data quality: false positives/negatives in compilation detection and extraction need tuning.
- Status inference (“open/closed”) is not inferred from Telegram updates; it only expires by age.
- Reliability: telemetry/monitoring and alerting are not yet production-grade.

Milestone 2 – Soft Monetisation: NOT IMPLEMENTED
- No payments, plans, entitlements, or pricing logic in codebase.

Milestone 3 – Tutor Behaviour Shift: NOT IMPLEMENTED (product + growth)
- No DM scale-out, reminders, cohorting, or retention tooling beyond basic profile + optional DMs.

Milestone 4 – Dependence via Personalisation: PARTIALLY IMPLEMENTED (foundation only)
Implemented:
- Tutor preference capture UI exists and is persisted (Redis + optional Supabase).
- Matching endpoint exists and DM sending is wired from the aggregator.
Gaps:
- Matching is still basic (subject/level/type/mode/tutor_kind); no geo radius, rate thresholds,
  ranking, or notification controls.
- No “why you matched”, “daily cap”, “delivery delay tiers”, or preference tuning UX loops.

Milestone 5 – Intelligence Accumulation: NOT IMPLEMENTED (beyond schema)
Implemented foundations:
- Data model and analytics_events table exist.
Gaps:
- No dashboards, market benchmarks, fill-rate estimates, competitiveness scoring, demand heatmaps, etc.

Milestone 6 – Application Flow Centralisation: NOT IMPLEMENTED
- Website currently links to the original Telegram message; there is no TutorDex-managed apply flow.

Milestone 7 – First Agency Dependence: NOT IMPLEMENTED
- No agency-facing portal, lead attribution, or “applications originated from TutorDex” reporting.

Milestone 8 – Scalable Agency Monetisation: NOT IMPLEMENTED
- No agency billing/commission system, contracts, invoicing, or analytics products.

================================================================================
5) Deliverables Needed for Public Beta (and V1.0 Launch)
================================================================================
This section is intentionally detailed: it is the “what to build” list.

----------------------------------------
Milestone 0 (Prerequisite): Public Beta Engineering Baseline
----------------------------------------
Goal: Make the existing pipeline shippable and supportable.

Deliverables:
1) Deployment & operations
   - Define a single “prod” deployment story:
     - Aggregator: Windows service or scheduled task (already has helper scripts) with watchdog,
       restart policies, and health reporting.
     - Backend: Docker compose already exists; add log persistence and a healthcheck.
     - Website: Firebase Hosting + CI already exists; ensure env var provisioning is correct.
   - Centralize configs:
     - Document required env vars per component (Aggregator/Backend/Website) and separate secrets.
   - Monitoring/alerting:
     - Alerts on: aggregator down, backlog, Telegram rate limits, LLM failures, Supabase failures,
       DM send failures, backend errors, Redis connection issues.
     - At minimum: log-based alerts + daily “pipeline health summary”.

2) Security and privacy reminders (even if “no constraints for now”)
   - Add explicit TODOs for: PII handling, consent, retention, data deletion, breach response,
     and what is considered sensitive (addresses, phone numbers, etc.).
   - Ensure secrets never appear in logs (currently generally respected; keep it that way).

3) Hardening the schema contract
   - Lock a versioned assignment schema (fields + types) that all components agree on.
   - Add a migration strategy for schema changes (Supabase table migrations + backwards-compat).

----------------------------------------
Milestone 1: Aggregation Accuracy (Finish to “trusted” level)
----------------------------------------
Goal: Tutors trust TutorDex as a legitimate source and it runs daily without intervention.

Deliverables (highest priority):
1) Ingestion coverage & robustness
   - Add more agencies/channels (with per-agency extraction examples in
     `TutorDexAggregator/message_examples/` and mappings in `extract_key_info.py`).
   - Rate-limit and resilience:
     - Ensure Telethon reconnection handling, flood-wait backoff, and long-run stability.
   - Improve compilation handling:
     - Tune thresholds (COMP_* env vars) to reduce false positives.
     - Decide a strategy:
       A) keep skipping compilations, or
       B) parse compilations into individual assignments (preferred for completeness).
     - Use `TutorDexAggregator/compilations.jsonl` as the test set for this work.

2) Deduplication + assignment lifecycle
   - Dedupe across:
     - re-posts in the same channel,
     - bumps (same code, different message id),
     - and cross-posts across agencies (harder; may require fuzzy matching).
   - Add a clear status model:
     - open / filled / closed / expired / unknown.
   - Add status inference signals:
     - edits that mark “filled/closed”,
     - follow-up posts that reference a code as taken,
     - time-to-fill heuristics.
   - Keep `expire_assignments.py` as a backstop, but don’t rely on “age only” for quality.

3) Data quality & validation
   - Define validation rules that reflect real posts:
     - Required: subject(s) + level (or recoverable) + some location signal (or “Online”).
     - Handle tuition-centre multi-slot details (the schema already supports slot_details).
   - Add extraction confidence fields:
     - model_confidence per field, or at minimum a top-level `parse_quality` score and reasons.
   - Add a “human review” pipeline for low-confidence posts:
     - moderation queue/topic in Telegram (there’s already skipped forwarding support).

4) Website data feed correctness
   - Ensure Supabase `assignments` table is consistently populated with the fields the website reads.
   - Ensure RLS policies for public beta:
     - Website anon key should only be able to read open assignments (see `supabase_rls_policies.sql`).

----------------------------------------
Milestone 4 (Public Beta Core): Dependence via Personalisation (Make DMs actually valuable)
----------------------------------------
Goal: Tutors rely on TutorDex DMs and stop scanning channels.

Deliverables:
1) Matching quality upgrades (needed for “sniper”)
   - Add geo filtering:
     - Store tutor location preference as either postal code(s), region, or lat/lng + radius.
     - For assignments, store location signals consistently (postal_code, region, maybe geocode).
   - Add rate thresholds and ranking:
     - Tutor min rate preferences; prefer higher rate jobs.
     - Prioritise best matches first (and cap DMs).
   - Add notification controls:
     - daily cap, quiet hours, “instant vs delayed”, and “broad vs strict” toggles.

2) DM pipeline reliability
   - Ensure tutors are actually being stored (Redis) and chat_id linking works end-to-end:
     - Website generates code -> DM bot receives /link -> backend claims -> tutor record updated.
   - Add DM delivery telemetry:
     - sent count, failures, per-assignment matched count, per-tutor delivery counts.
   - Add abuse controls:
     - per-tutor DM rate limits, spam safeguards, unsubscribe/mute.

3) UX loops that create “dependence”
   - On the website:
     - “Matched you X times in 7 days” (requires event tracking).
     - “Your top missed categories” (requires apply/engagement tracking).
   - In Telegram:
     - DM template should include “why matched” and a clear apply CTA.

----------------------------------------
Milestone 5: Intelligence Accumulation (Analytics Product Foundations)
----------------------------------------
Goal: TutorDex knows the market better than any single agency.

Deliverables (data + analytics; concrete list):
1) Expand event tracking (backend `/analytics/event`)
   - Tutor journey events:
     - sign_up, sign_in
     - profile_save (already)
     - telegram_link_success
     - assignments_view (already)
     - filter_apply (level/subject/rate/location selections)
     - assignment_open (view details)
     - assignment_click_source (clicked Telegram source link)
     - DM_sent / DM_delivered (system-side), DM_click_apply (user-side)
   - Application funnel events (requires Milestone 6):
     - apply_start, apply_submit, agency_response, applied_success/failed/unknown

2) Add computed market metrics (stored daily in Supabase)
   - Supply/demand:
     - assignments per day by subject/level/region/mode
     - tutor preference distributions by subject/level/region
   - Price:
     - median/p25/p75 rates by category (subject+level+mode+region)
   - Velocity/competition:
     - time-to-fill estimates (needs status inference + closure signals)
     - bump_count as a proxy for reposting/urgency
   - Data quality:
     - extraction success rate, validation fail rate, % with missing postal/time/rate

3) Dashboards (internal first)
   - A simple internal dashboard (could be Supabase Studio views initially) for:
     - ingestion volume by channel
     - failure rates (LLM/Supabase/Telegram)
     - top categories and trendlines
     - tutor signups and link rates

----------------------------------------
Milestone 6: Application Flow Centralisation (Needed for agency monetisation)
----------------------------------------
Goal: Applications start flowing through TutorDex so attribution is measurable.

Deliverables:
1) A TutorDex “Apply” action
   - Replace “apply via agency” with a TutorDex-managed apply click/flow:
     - at minimum: tracked redirect
     - better: a standard application form that forwards to the agency/contact method
   - Capture attribution:
     - which tutor applied, to which assignment, when, via which channel (DM vs website)

2) Assignment detail pages
   - Website needs per-assignment pages with:
     - details, apply button, source transparency (per background doc), and tracking hooks.

3) Agency contact plumbing
   - Normalize “how to apply” per agency:
     - Telegram link, form link, WhatsApp, email.
   - Store these contact endpoints in the assignment record where possible.

----------------------------------------
Milestone 2: Soft Monetisation (after DMs are valuable)
----------------------------------------
Goal: Tutors optionally pay for “advantage” features without backlash.

Deliverables:
1) Plan and entitlements system
   - Free vs paid feature gates:
     - tighter geo radius, stricter filters, higher DM caps, faster delivery, better ranking.
   - Implement payments:
     - Stripe (typical) or local alternative; store subscriptions and entitlement state.

2) Paid delivery behavior
   - Priority queueing and consistent delivery guarantees for paid tier.
   - Audit logs: who got which DM when, and why (to support trust).

----------------------------------------
Milestone 7–8: Agency Dependence + Monetisation (Agency-first V1.0)
----------------------------------------
Goal: Agencies pay because TutorDex measurably improves fill rates and speed-to-fill.

Deliverables:
1) Agency-facing portal (beta)
   - Agency accounts, onboarding, and reporting:
     - applications received from TutorDex
     - fill speed and conversion metrics
     - category demand insights
   - “Post a job” interface for agencies (optional but powerful):
     - structured submission reduces extraction errors and creates higher-quality data.

2) Commission / billing model
   - Define:
     - per-filled assignment commission, per-lead pricing, or monthly subscription tiers.
   - Implement:
     - invoicing, reconciliation, dispute handling, and refund logic.

3) Anti-scrape / censorship strategy (from the background doc)
   - Implement progressive disclosure:
     - public channel shows limited fields once competition arises;
     - full details in DMs/website for authenticated users.
   - Add bot protections:
     - rate limits, watermarking, delayed feeds, and monitoring for scraping patterns.

================================================================================
6) Notable Issues / Risks Observed (from logs + code)
================================================================================
1) Telethon performance warning
- Logs show: cryptg module not installed and SSL lib not found, falling back to slower encryption.
- For a long-running ingestion service, install cryptg and ensure OpenSSL is available to avoid
  unnecessary CPU use and potential instability.

2) Compilation detection needs tuning/verification
- `compilations.jsonl` contains many entries; treat it as both:
  - a quality control dataset, and
  - a backlog for parsing multi-assignment posts.
- Confirm whether it is skipping only true compilations or also skipping valid single posts.

3) DM matching likely not “live” yet
- Aggregator logs show DM steps with “no matches” or failures; this usually means:
  - DM_ENABLED is off, or
  - no tutors are stored/linked in Redis, or
  - backend/admin key mismatch, or
  - matching thresholds too strict.
This is expected early, but must be validated end-to-end for public beta.

================================================================================
7) “Next 7 Days” Suggested Sprint Plan (to reach a credible Public Beta)
================================================================================
Day 1–2: Stabilise ingestion + Supabase feed
- Validate compilation detection and fix false positives.
- Ensure assignment schema consistency; confirm website shows real Supabase assignments.
- Add a daily health summary and basic alerting.

Day 3–4: Make preferences + DM pipeline work end-to-end
- Ensure profile saves create usable Redis tutor records.
- Validate link-code flow; confirm chat_id is set and DMs deliver to real users.
- Add DM telemetry + per-user caps.

Day 5–7: Analytics + small “dependence” hooks
- Add event tracking for apply clicks (even if still redirected to source).
- Add simple tutor-facing stats: matches/week, DMs sent/week, top subjects seen.
- Add internal dashboard queries (Supabase views or scripts) for ingestion volume and failures.

================================================================================
8) Reference Map (where to look in code)
================================================================================
Aggregator:
- Entry: TutorDexAggregator/runner.py
- Reader: TutorDexAggregator/read_assignments.py
- Extraction: TutorDexAggregator/extract_key_info.py + TutorDexAggregator/message_examples/
- Broadcast: TutorDexAggregator/broadcast_assignments.py
- DM sending: TutorDexAggregator/dm_assignments.py
- Supabase persistence: TutorDexAggregator/supabase_persist.py
- Closing stale: TutorDexAggregator/expire_assignments.py
- Analytics rollup: TutorDexAggregator/analytics_rollup.py

Backend:
- API: TutorDexBackend/app.py
- Redis store: TutorDexBackend/redis_store.py
- Matching: TutorDexBackend/matching.py
- Supabase store: TutorDexBackend/supabase_store.py
- Telegram link bot poller: TutorDexBackend/telegram_link_bot.py

Website:
- Landing: TutorDexWebsite/index.html + TutorDexWebsite/auth.js
- Assignments: TutorDexWebsite/assignments.html + TutorDexWebsite/src/page-assignments.js
- Profile: TutorDexWebsite/profile.html + TutorDexWebsite/src/page-profile.js
- Supabase client: TutorDexWebsite/src/supabase.js
- Backend client + event tracking: TutorDexWebsite/src/backend.js

