# =============================================================================
# TutorDexAggregator Environment Configuration (Pydantic-Settings Format)
# =============================================================================
# 
# This file is generated from the Pydantic schema in shared/config.py
# It represents the FUTURE configuration format when migration is complete.
#
# Current Status: üöß NOT YET IN USE
# The service still uses the legacy .env.example format
# See docs/PYDANTIC_CONFIG.md for full documentation
#
# Instructions:
# 1. Copy this file to TutorDexAggregator/.env
# 2. Fill in the required values (marked REQUIRED)
# 3. Customize optional values as needed
# 4. Never commit .env files to git
#
# =============================================================================

# =============================================================================
# SUPABASE PERSISTENCE (REQUIRED)
# =============================================================================
# Get these from your Supabase project dashboard

# Supabase project URL
# Format: https://<project-ref>.supabase.co or http://supabase-kong:8000 (self-hosted)
SUPABASE_URL=  # REQUIRED

# Supabase service role key (has full database access)
# Get from: Supabase Dashboard ‚Üí Settings ‚Üí API ‚Üí service_role key
# ‚ö†Ô∏è KEEP SECRET: Never commit this value
SUPABASE_KEY=  # REQUIRED


# =============================================================================
# PIPELINE VERSIONING
# =============================================================================
# Controls extraction job isolation and reprocessing

# Pipeline version for extraction queue isolation
# Change this to create a new isolated extraction run (e.g., for backfills)
# Format: YYYY-MM-DD_description (e.g., 2026-01-02_det_time_v1)
EXTRACTION_PIPELINE_VERSION=2026-01-02_det_time_v1

# Canonical JSON schema version
# Only bump for breaking changes to the parsed output structure
# Format: YYYY-MM-DD (e.g., 2026-01-01)
SCHEMA_VERSION=2026-01-01


# =============================================================================
# EXTRACTION WORKER CONFIGURATION
# =============================================================================
# Controls the extraction queue worker behavior

# Maximum retry attempts for failed extractions
# Range: 1-10, Default: 3
EXTRACTION_MAX_ATTEMPTS=3

# Number of jobs to process per batch
# Higher = more throughput, lower = less memory usage
# Default: 10
EXTRACTION_WORKER_BATCH_SIZE=10

# Polling interval for extraction queue (seconds)
# How often to check for new jobs when queue is empty
# Default: 5
EXTRACTION_WORKER_POLL_SECONDS=5

# Process one batch and exit (for testing/validation)
# Use Mode 4 (oneshot validation) from docs/recovery_catchup.md
# Default: false
EXTRACTION_WORKER_ONESHOT=false


# =============================================================================
# LLM API CONFIGURATION (REQUIRED FOR EXTRACTION)
# =============================================================================
# OpenAI-compatible LLM API for parsing assignments

# LLM API URL
# - Docker: http://host.docker.internal:1234 (reaches host from container)
# - Host: http://127.0.0.1:1234 (LM Studio or llama.cpp server)
# - Remote: https://api.your-llm-service.com
LLM_API_URL=http://host.docker.internal:1234

# Model name to use for extraction
# - LM Studio: Usually "default" or specific model name
# - OpenAI: "gpt-4o-mini", "gpt-4", etc.
# Default: default
LLM_MODEL_NAME=default

# Circuit breaker: consecutive failures before circuit opens
# Prevents queue burn when LLM is unavailable
# Default: 5
LLM_CIRCUIT_BREAKER_THRESHOLD=5

# Circuit breaker: seconds to wait before retrying after circuit open
# Gives LLM time to recover before retrying
# Default: 60
LLM_CIRCUIT_BREAKER_TIMEOUT_SECONDS=60


# =============================================================================
# SIDE-EFFECTS (OPT-IN FOR WORKER)
# =============================================================================
# Control which side-effects the extraction worker performs
# Recommended: Disable broadcast/DMs for backfills and testing

# Send assignments to broadcast Telegram channel
# Set false for testing or backfills
# Default: false
ENABLE_BROADCAST=false

# Send DMs to matched tutors
# Set false for testing or backfills
# Default: false
ENABLE_DMS=false

# Persist assignments to Supabase
# Set false only for dry-run testing
# Default: true
ENABLE_PERSISTENCE=true


# =============================================================================
# TELEGRAM API CONFIGURATION
# =============================================================================
# Required for collector and bots

# Telegram API ID from my.telegram.org
# Get from: https://my.telegram.org/apps
TELEGRAM_API_ID=

# Telegram API hash from my.telegram.org
# Get from: https://my.telegram.org/apps
# ‚ö†Ô∏è KEEP SECRET: Never commit this value
TELEGRAM_API_HASH=

# Session file name for Telegram client
# The .session file stores authentication
# Default: tutordex_collector
TELEGRAM_SESSION_NAME=tutordex_collector

# Bot token for Telegram bot (for broadcasting/DMs)
# Get from: @BotFather on Telegram
# Format: 123456:ABC-DEF1234ghIkl-zyx57W2v1u123ew11
# ‚ö†Ô∏è KEEP SECRET: Never commit this value
TELEGRAM_BOT_TOKEN=


# =============================================================================
# OBSERVABILITY CONFIGURATION
# =============================================================================
# OpenTelemetry, Prometheus, and logging

# Enable OpenTelemetry tracing
# Sends traces to OTEL collector for distributed tracing
# Default: false
OTEL_ENABLED=false

# OTLP HTTP endpoint for traces
# - Docker Compose: http://otel-collector:4318
# - External: https://your-otel-endpoint.com
# Default: http://otel-collector:4318
OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318

# Service name for tracing
# Appears in Tempo/Jaeger traces
# Default: tutordex-aggregator
OTEL_SERVICE_NAME=tutordex-aggregator

# Port to expose Prometheus metrics
# Metrics available at http://localhost:8001/metrics
# Default: 8001
PROMETHEUS_PORT=8001

# Logging level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
LOG_LEVEL=INFO


# =============================================================================
# SENTRY ERROR TRACKING (OPTIONAL)
# =============================================================================
# Cloud-hosted error monitoring and performance tracking

# Sentry DSN for error reporting
# Get from: Sentry.io ‚Üí Project Settings ‚Üí Client Keys (DSN)
# Format: https://<public_key>@o<org_id>.ingest.sentry.io/<project_id>
# Leave empty to disable Sentry
SENTRY_DSN=

# Sentry environment name
# Helps filter errors by environment in Sentry UI
# Options: development, staging, production
# Default: production
SENTRY_ENVIRONMENT=production


# =============================================================================
# NOTES ON MIGRATION
# =============================================================================
#
# This file represents the FUTURE state after Pydantic migration.
# Currently, the service uses the legacy .env.example format.
#
# Key differences from legacy format:
# 1. Fewer fields (only those in AggregatorConfig)
# 2. Clearer required vs. optional distinction
# 3. Type-safe defaults enforced by Pydantic
# 4. No manual type conversion helpers needed (_truthy, _env_int)
# 5. Automatic validation at startup
#
# Legacy features NOT in Pydantic config (yet):
# - CHANNEL_LIST (Telegram channels to monitor)
# - HISTORIC_FETCH (backfill mode)
# - LLM_SYSTEM_PROMPT_FILE (prompt overrides)
# - NOMINATIM_* (geocoding settings)
# - GROUP_BOT_TOKEN (broadcast bot)
# - DM_BOT_TOKEN (DM bot)
# - And ~50 more legacy settings
#
# These will be migrated incrementally during adoption.
# See docs/PYDANTIC_CONFIG.md for full migration guide.
#
# =============================================================================
