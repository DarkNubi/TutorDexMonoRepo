# TutorDexAggregator/.env.example
# Copy to `TutorDexAggregator/.env` and fill values. Do NOT commit secrets.

# ----------------------------
# Telegram reader (required)
# ----------------------------
TELEGRAM_API_ID=
TELEGRAM_API_HASH=
CHANNEL_LIST=["t.me/TuitionAssignmentsSG","t.me/tuitionassignmentsttrsg","t.me/TutorAnywhr","t.me/elitetutorsg","t.me/FTassignments"]

# Optional reader tuning
# HISTORIC_FETCH=0
# PROCESSED_STORE=processed_ids.json
# TELEGRAM_MAX_RETRIES=5
# TELEGRAM_INITIAL_RETRY_DELAY=1.0
# TELEGRAM_MAX_RETRY_DELAY=300.0
# TELEGRAM_BACKOFF_MULTIPLIER=2.0

# ----------------------------
# Telegram session (choose one)
# ----------------------------
# SESSION_STRING=
# TG_SESSION=tutordex.session

# ----------------------------
# LLM (required for extraction)
# ----------------------------
LLM_API_URL=http://host.docker.internal:1234
# LLM_MODEL_NAME=nuextract-v1.5@q6_k_l
# LLM_TIMEOUT_SECONDS=200

# ----------------------------
# llama.cpp server (optional)
# ----------------------------
# If set, `python runner.py queue --start-llama` can start llama-server for you.
# LLAMA_SERVER_EXE=C:\\llama-bin\\llama-server.exe
# LLAMA_MODEL_PATH=C:\\models\\LFM2-8B-A1B-Q4_K_M.gguf
# LLAMA_SERVER_HOST=127.0.0.1
# LLAMA_SERVER_PORT=1234
# LLAMA_CTX=8192
# LLAMA_THREADS=6
# LLAMA_BATCH=512
# LLAMA_NGL=999
# LLAMA_SERVER_ARGS=

# Optional: Nominatim User-Agent (recommended if you do heavy backfills)
# NOMINATIM_USER_AGENT=TutorDexAggregator/1.0 (your-email@example.com)

# Optional enrichment toggles
# DISABLE_NOMINATIM=false
# LOG_ASSIGNMENT_JSON=false

# ----------------------------
# Bot 1: Broadcast to channel (optional)
# ----------------------------
# GROUP_BOT_TOKEN=
# AGGREGATOR_CHANNEL_ID=
# BOT_API_URL=
# BROADCAST_FALLBACK_FILE=outgoing_broadcasts.jsonl
# BROADCAST_MAX_REMARKS_LEN=700
# BROADCAST_MAX_MESSAGE_LEN=3900

# ----------------------------
# Skipped/moderation forwarding (optional)
# ----------------------------
# SKIPPED_MESSAGES_CHAT_ID=
# SKIPPED_MESSAGES_THREAD_ID=

# ----------------------------
# Bot 2: DM sending + matching backend (optional)
# ----------------------------
# DM_ENABLED=false
# DM_BOT_TOKEN=
# DM_BOT_API_URL=
# TUTOR_MATCH_URL=http://127.0.0.1:8000/match/payload
# BACKEND_API_KEY=
# DM_MAX_RECIPIENTS=50
# DM_FALLBACK_FILE=outgoing_dm.jsonl

# ----------------------------
# Supabase persistence (optional)
# ----------------------------
# Enable with SUPABASE_ENABLED=true
# SUPABASE_ENABLED=false
# SUPABASE_URL=https://<project-ref>.supabase.co            # Supabase Cloud
# SUPABASE_URL=https://supabase-api.example.com             # Supabase self-host (Kong public URL; no /rest/v1 suffix)
# SUPABASE_SERVICE_ROLE_KEY=
# SUPABASE_ASSIGNMENTS_TABLE=assignments
# SUPABASE_BUMP_MIN_SECONDS=21600

# ----------------------------
# Raw Telegram persistence (optional, recommended for backfill)
# ----------------------------
# Persists lossless message history for reprocessing/dedupe/analytics.
# Defaults to SUPABASE_ENABLED if SUPABASE_RAW_ENABLED is not set.
# SUPABASE_RAW_ENABLED=true
# SUPABASE_RAW_CHANNELS_TABLE=telegram_channels
# SUPABASE_RAW_MESSAGES_TABLE=telegram_messages_raw
# SUPABASE_RAW_RUNS_TABLE=ingestion_runs
# SUPABASE_RAW_PROGRESS_TABLE=ingestion_run_progress
#
# Optional local fallback (writes JSONL when Supabase raw is disabled/unavailable):
# RAW_FALLBACK_FILE=raw_messages_fallback.jsonl

# ----------------------------
# Subject taxonomy (optional, recommended)
# ----------------------------
# Adds derived arrays for hierarchical filtering + analytics:
# - subjects_general (broad categories like MATH)
# - subjects_canonical (advanced codes like MATH.SEC_EMATH)
#
# SUBJECT_TAXONOMY_ENABLED=false
# SUBJECT_TAXONOMY_DEBUG=false  # Only enable if you also add a `canonicalization_debug` jsonb column.
# SUBJECT_TAXONOMY_PATH=taxonomy/subjects_taxonomy_v1.json

# ----------------------------
# Logging (optional)
# ----------------------------
# LOG_LEVEL=INFO
# LOG_JSON=false
# LOG_DIR=logs
# LOG_TO_CONSOLE=true
# LOG_TO_FILE=true
# LOG_FILE=tutordex_aggregator.log
# LOG_MAX_BYTES=5000000
# LOG_BACKUP_COUNT=5

# ----------------------------
# Monitoring / alerting (optional, recommended)
# ----------------------------
# Heartbeat file written by the aggregator (used by monitor.py)
# HEARTBEAT_FILE=monitoring/heartbeat.json
# HEARTBEAT_TICK_SECONDS=60
#
# Heartbeat file written by the raw collector (`python collector.py ...`)
# RAW_HEARTBEAT_FILE=monitoring/heartbeat_raw_collector.json
#
# Telegram alert destination (recommend: a private admin group + a dedicated thread)
# ALERT_BOT_TOKEN=            # can reuse GROUP_BOT_TOKEN, but better to use a separate bot token
# ALERT_CHAT_ID=              # numeric chat id (e.g. -100...)
# ALERT_THREAD_ID=            # optional topic/thread id inside the chat
# ALERT_PREFIX=[TutorDex Monitor]
#
# Monitor loop settings
# MONITOR_CHECK_INTERVAL_SECONDS=15
# ALERT_COOLDOWN_SECONDS=600
# ALERT_HEARTBEAT_STALE_SECONDS=900
# ALERT_LOG_STALE_SECONDS=900
# ALERT_ERROR_BURST_LIMIT=6

# ----------------------------
# Click tracking (tracked links + broadcast click count)
# ----------------------------
# TRACKING_BASE_URL=http://127.0.0.1:8000
# CLICK_TRACKING_SECRET=change-me

# ----------------------------
# TutorCity API fetch (no LLM)
# ----------------------------
# TUTORCITY_API_URL=https://tutorcity.sg/api/tuition-assignments/
# TUTORCITY_LIMIT=50
# TUTORCITY_TIMEOUT_SECONDS=30
# TUTORCITY_FETCH_INTERVAL_SECONDS=300
# TUTORCITY_USER_AGENT=TutorDexTutorCityFetcher/1.0
#
# Backend health aggregation (checks backend + redis + supabase via /health/full)
# MONITOR_BACKEND_HEALTH_URL=http://127.0.0.1:8000/health/full
#
# Daily summary (local time)
# DAILY_SUMMARY_ENABLED=true
# DAILY_SUMMARY_HOUR_LOCAL=9

# ----------------------------
# Telegram edit/delete monitor (optional)
# ----------------------------
# Records message edits and deletions for CHANNEL_LIST into a local SQLite DB.
# Useful because some agencies edit posts after publishing.
#
# Run:
# - `python monitor_message_edits.py`
#
# EDIT_MONITOR_DB_PATH=monitoring/telegram_message_edits.sqlite
# EDIT_MONITOR_EVENTS_JSONL=monitoring/telegram_message_edits_events.jsonl
# EDIT_MONITOR_INCLUDE_TEXT=true
# EDIT_MONITOR_MAX_TEXT_CHARS=20000
# EDIT_MONITOR_HISTORIC_FETCH=50
# EDIT_MONITOR_SUMMARY_INTERVAL_SECONDS=600

# ----------------------------
# Freshness tier updater (optional)
# ----------------------------
# Example scheduled runs:
# - `python update_freshness_tiers.py --dry-run`
# - `python update_freshness_tiers.py --expire-action none`
#
# FRESHNESS_TIER_ENABLED=false  # set true after applying the migration
# FRESHNESS_TIERS_INTERVAL_SECONDS=3600  # docker sidecar cadence (default: hourly)
# FRESHNESS_TIERS_ARGS="--expire-action closed --red-hours 336"  # passed to update_freshness_tiers.py

# ----------------------------
# Extraction worker tuning (queue pipeline)
# ----------------------------
# EXTRACTION_PIPELINE_VERSION=singlecall_v1
# EXTRACTION_WORKER_BATCH=10
# EXTRACTION_WORKER_IDLE_S=2
# EXTRACTION_WORKER_BROADCAST=0   # recommended for backfills
# EXTRACTION_WORKER_DMS=0         # recommended for backfills
